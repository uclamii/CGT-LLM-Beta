# RAG Chatbot with Vector Database

A production-ready Retrieval-Augmented Generation (RAG) chatbot built in Python that runs efficiently on Apple Silicon (M2 Max) using MPS acceleration. The system processes documents from local folders, answers questions using a vector database for fast retrieval, and outputs results to CSV files.

## ğŸš€ Features

- **âš¡ Lightning Fast Retrieval**: ChromaDB vector database with sub-second query times
- **ğŸ§  Advanced Language Model**: Llama-3.2-3B-Instruct for high-quality medical responses
- **ğŸ Apple Silicon Optimized**: Full MPS acceleration support for M2 Max
- **ğŸ“Š Persistent Storage**: Vector embeddings cached for instant reuse
- **ğŸ“ Multi-format Support**: Handles TXT, MD, JSON, CSV, PDF, and DOCX files
- **ğŸ¯ Semantic Search**: Sentence-transformers for intelligent document retrieval
- **ğŸ“‹ Source Attribution**: Automatic source document tracking for transparency
- **ğŸ’¾ Incremental Saving**: Progress saved after each question for reliability
- **ğŸ“š Readability Enhancement**: Automatic 6th-grade level simplification with Flesch-Kincaid scoring
- **ğŸ“ˆ Production Ready**: Comprehensive logging, error handling, and CLI interface

## ğŸ“‹ Requirements

- Python 3.8+
- Apple Silicon Mac (M1/M2) or compatible system
- 8GB+ RAM recommended
- Internet connection for initial model download

## ğŸ› ï¸ Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd CGT-LLM-Beta
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Verify installation:**
   ```bash
   python bot.py --help
   ```

## ğŸ“ Project Structure

```
CGT-LLM-Beta/
â”œâ”€â”€ bot.py                    # Main RAG chatbot script
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ results/                 # Generated CSV outputs
â”œâ”€â”€ chromadb/                # Vector database storage
â””â”€â”€ Data Resources/          # Source documents
```

## ğŸš€ Quick Start

### First Run (Build Vector Database)
```bash
python bot.py --questions question.txt --out answers.csv --vector-db-dir ./chromadb
```

### Subsequent Runs (Lightning Fast!)
```bash
python bot.py --questions question.txt --out answers.csv --skip-indexing --vector-db-dir ./chromadb
```

## ğŸ“– Usage

### Basic Usage
```bash
python bot.py --questions <input_file> --out <output_file>
```

### Advanced Options
```bash
python bot.py \
  --questions question.txt \
  --out results/answers.csv \
  --vector-db-dir ./chroma_db \
  --k 5 \
  --temperature 0.7 \
  --max-new-tokens 512 \
  --verbose
```

### Command Line Arguments

| Argument | Description | Default |
|----------|-------------|---------|
| `--questions` | Input questions file (one per line) | Required |
| `--out` | Output CSV file path | Required |
| `--data-dir` | Directory containing source documents | `./Data Resources` |
| `--vector-db-dir` | Vector database storage directory | `./chromadb` |
| `--k` | Number of chunks to retrieve | `3` |
| `--chunk-size` | Document chunk size in tokens | `400` |
| `--chunk-overlap` | Overlap between chunks | `150` |
| `--max-new-tokens` | Maximum tokens to generate | `1024` |
| `--temperature` | Generation temperature (0.0-1.0) | `0.8` |
| `--top-p` | Top-p sampling parameter | `0.9` |
| `--repetition-penalty` | Repetition penalty factor | `1.1` |
| `--force-rebuild` | Force rebuild vector database | `False` |
| `--skip-indexing` | Skip document indexing | `False` |
| `--verbose` | Enable detailed logging | `False` |
| `--dry-run` | Test mode without generation | `False` |

## ğŸ“Š Input/Output Format

### Input File (`question.txt`)
```
What is Lynch Syndrome?
How does genetic testing work?
What are the symptoms of cancer?
```

### Output File (`results/answers.csv`)
```csv
question,answer,sources,6th_grade_answer,flesch_kincaid_grade_level
"What is Lynch Syndrome?","According to the text, Lynch syndrome (also known as hereditary nonpolyposis colorectal cancer) is: * An autosomal dominant disorder * Refers to individuals and/or families who have a pathogenic germline mutation in one of the DNA mismatch repair genes (MLH1, MSH2, MSH6, and PMS2) or the EPCAM gene. * Can be transmitted by either parent to approximately 50% of offspring. It is characterized by an increased risk of developing various types of cancer, including colorectal, endometrial, ovarian, stomach, small bowel, pancreatobiliary system, genitourinary system (urothelial cancer), prostate, brain, and skin cancers, as well as breast cancer in some cases.","Lynch syndrome (hereditary nonpolyposis colorectal cancer)_ Cancer screening and management - UpToDate; uterine; ovarian-ukrainian","Here's a rewritten version of the text in simpler language: **What is Lynch Syndrome?** Lynch syndrome is a condition that runs in families. It's caused by a problem with our DNA. This problem can be passed down from one parent to their child. **What happens in people with Lynch syndrome?** People with Lynch syndrome are more likely to get certain types of cancer. These include: * Colorectal cancer (which affects the colon) * Cancer of the uterus (endometrial cancer) * Ovarian cancer * Stomach cancer * Pancreas cancer * Cancer of the bile ducts * Bladder cancer * Prostate cancer * Brain cancer * Skin cancer * Breast cancer (in some cases) **How does it work?** The problem with Lynch syndrome is that our bodies have trouble fixing mistakes in our DNA. This makes us more likely to develop cancer. It's not because of anything we did or didn't do, but just because of how our DNA works. I hope this helps! Let me know if you'd like me to simplify anything further.",6.2
"How does genetic testing work?","Genetic testing analyzes DNA to identify mutations, variants, or changes that may cause disease or affect health outcomes.","genetics_ceg; Cancer risks in BRCA1_2 carriers - UpToDate","Genetic testing is like looking at a recipe book for your body. It checks your DNA (which is like the instructions that tell your body how to work) to see if there are any mistakes or changes that might cause health problems.","5.8"
```

## ğŸ”§ Configuration

### Model Settings
- **Model**: `meta-llama/Llama-3.2-3B-Instruct`
- **Device**: Automatic MPS detection for Apple Silicon
- **Precision**: `torch.float16` on MPS, `torch.float32` on CPU

### Vector Database
- **Embedding Model**: `all-MiniLM-L6-v2` (384 dimensions)
- **Database**: ChromaDB with HNSW indexing
- **Collection**: `cgt_documents`

### Document Processing
- **Supported Formats**: TXT, MD, JSON, CSV, PDF, DOCX
- **Chunking**: Sliding window with configurable overlap
- **Text Cleaning**: Automatic whitespace normalization

## ğŸ¯ Performance

### Speed Improvements
- **Initial Indexing**: ~30 seconds for 8,964 documents
- **Subsequent Queries**: <1 second retrieval time
- **Generation**: ~7-20 seconds per question (optimized settings)
- **Readability Enhancement**: ~35 seconds per question (additional LLM call)
- **Incremental Saving**: Progress saved after each question

### Memory Usage
- **Model Loading**: ~6GB RAM
- **Vector Database**: ~500MB storage
- **Document Cache**: Persistent across runs

## ğŸ” Troubleshooting

### Common Issues

**1. Model Download Errors**
```bash
# Clear Hugging Face cache
rm -rf ~/.cache/huggingface/
python bot.py --questions test.txt --out test.csv
```

**2. MPS Not Available**
```bash
# Check PyTorch MPS support
python -c "import torch; print(torch.backends.mps.is_available())"
```

**3. Vector Database Corruption**
```bash
# Rebuild vector database
python bot.py --questions test.txt --out test.csv --force-rebuild --vector-db-dir ./chromadb
```

**4. Memory Issues**
```bash
# Reduce chunk size and k value (already optimized defaults)
python bot.py --questions test.txt --out test.csv --k 2 --chunk-size 300
```

**5. Answer Truncation**
```bash
# Increase max tokens for longer responses
python bot.py --questions test.txt --out test.csv --max-new-tokens 1024
```

### Debug Mode
```bash
python bot.py --questions test.txt --out test.csv --verbose --dry-run
```

## ğŸ“ˆ Examples

### Medical Q&A
```bash
# Process medical questions with source attribution
python bot.py \
  --questions medical_questions.txt \
  --out results/medical_answers.csv \
  --vector-db-dir ./chromadb \
  --k 3 \
  --temperature 0.8 \
  --max-new-tokens 1024 \
  --verbose
```

### Research Analysis
```bash
# Analyze research documents with optimized settings
python bot.py \
  --questions research_questions.txt \
  --out results/research_analysis.csv \
  --data-dir ./Research_Papers \
  --vector-db-dir ./chromadb \
  --k 3 \
  --max-new-tokens 1024 \
  --temperature 0.8
```

## âœ¨ Recent Improvements

### Version 2.0 Features
- **ğŸ“‹ Source Attribution**: Every answer now includes the source documents used
- **ğŸ’¾ Incremental Saving**: Progress automatically saved after each question
- **âš¡ Optimized Performance**: Faster generation with improved parameters
- **ğŸ”§ Better Error Handling**: Robust error recovery and logging
- **ğŸ“Š Enhanced Output**: 5-column CSV format (question, answer, sources, 6th_grade_answer, flesch_kincaid_grade_level)
- **ğŸ“š Readability Enhancement**: Automatic simplification to 6th-grade reading level

### Key Optimizations
- **Model**: Upgraded to Llama-3.2-3B-Instruct for better instruction following
- **Context Management**: Dynamic truncation to prevent token overflow
- **Generation Parameters**: Optimized temperature (0.8) and max tokens (1024)
- **Chunk Size**: Reduced to 400 tokens for better context fitting
- **Retrieval**: Default k=3 for optimal balance of context and speed

### Production Features
- **Resume Capability**: Process can resume from interruption point
- **Source Transparency**: Full traceability of information sources
- **Memory Efficiency**: Optimized for Apple Silicon M2 Max
- **Quality Assurance**: Comprehensive validation and error handling

## ğŸ“š Readability Enhancement

### Two-Stage Processing Pipeline
1. **Medical Answer Generation**: Original detailed medical response
2. **Readability Enhancement**: Simplified version for 6th-grade reading level

### Features
- **Automatic Simplification**: Complex medical terms converted to everyday language
- **Flesch-Kincaid Scoring**: Objective readability measurement (target: 6.0)
- **Preserved Information**: All important medical facts maintained
- **Dual Output**: Both original and simplified versions provided

### Example Transformation
**Original**: "Lynch syndrome is an autosomal dominant disorder characterized by pathogenic germline mutations in DNA mismatch repair genes..."

**Simplified**: "Lynch syndrome is a condition that runs in families. It's caused by a problem with our DNA. This problem can be passed down from one parent to their child."

### Grade Level Interpretation
- **6.0-7.0**: Target range for accessibility
- **8.0-10.0**: Acceptable for general audience
- **11.0+**: May need further simplification

## ğŸ—ï¸ Architecture

### System Overview
```mermaid
graph TB
    subgraph "Input Layer"
        A[Questions File<br/>question.txt] --> B[CLI Interface<br/>bot.py]
        C[Data Resources<br/>PDF, TXT, MD, etc.] --> D[Document Loader]
    end
    
    subgraph "Processing Layer"
        D --> E[Text Chunking<br/>800 tokens, 150 overlap]
        E --> F[Sentence Transformers<br/>all-MiniLM-L6-v2]
        F --> G[Vector Embeddings<br/>384 dimensions]
    end
    
    subgraph "Storage Layer"
        G --> H[ChromaDB<br/>Vector Database]
        H --> I[HNSW Index<br/>Fast Retrieval]
    end
    
    subgraph "Query Processing"
        B --> J[Query Embedding<br/>Same Transformer]
        J --> K[Similarity Search<br/>Cosine Distance]
        K --> L[Top-K Chunks<br/>Relevance Scoring]
    end
    
    subgraph "Generation Layer"
        L --> M[Context Assembly<br/>Prompt Formatting]
        M --> N[Llama-3.2-3B-Instruct<br/>MPS Accelerated]
        N --> O[Answer Generation<br/>Medical Responses]
        O --> R[Readability Enhancement<br/>6th Grade Simplification]
        R --> S[Flesch-Kincaid<br/>Grade Level Calculation]
    end
    
    subgraph "Output Layer"
        S --> P[CSV Results<br/>5 columns with readability]
        L --> Q[Source Attribution<br/>Document Tracking]
        Q --> P
        I --> K
    end
    
    style A fill:#e1f5fe
    style C fill:#e1f5fe
    style H fill:#f3e5f5
    style N fill:#fff3e0
    style P fill:#e8f5e8
    style R fill:#e8f5e8
    style S fill:#fff3e0
```

### Architecture Flow
1. **Document Loading**: Recursive file traversal with format detection
2. **Text Processing**: Chunking with overlap and metadata preservation
3. **Embedding Generation**: Sentence-transformers for semantic vectors
4. **Vector Storage**: ChromaDB with HNSW indexing for fast retrieval
5. **Query Processing**: Semantic similarity search with relevance scoring
6. **Answer Generation**: Llama-3.2-3B-Instruct with context injection
7. **Readability Enhancement**: Second LLM call for 6th-grade simplification
8. **Grade Level Calculation**: Flesch-Kincaid scoring for accessibility
9. **Source Attribution**: Automatic tracking of source documents
10. **Incremental Output**: Progress saved after each question

### Data Flow Diagram
```mermaid
sequenceDiagram
    participant User
    participant CLI as CLI Interface
    participant Loader as Document Loader
    participant Chunker as Text Chunker
    participant Embedder as Sentence Transformer
    participant DB as ChromaDB
    participant Retriever as Vector Retriever
    participant LLM as Llama-3.2-3B
    participant Readability as Readability Enhancer
    participant Output as CSV Output
    participant Sources as Source Tracker
    
    Note over User,Output: Initial Setup (One-time)
    User->>CLI: python bot.py --questions q.txt --out a.csv
    CLI->>Loader: Load documents from Data Resources/
    Loader->>Chunker: Split into 800-token chunks
    Chunker->>Embedder: Generate embeddings
    Embedder->>DB: Store vectors in ChromaDB
    Note over DB: 8,964 documents indexed<br/>Persistent storage
    
    Note over User,Output: Query Processing (Fast)
    User->>CLI: Ask question
    CLI->>Retriever: Generate query embedding
    Retriever->>DB: Similarity search (cosine)
    DB-->>Retriever: Top-K relevant chunks
    Retriever->>Sources: Track source documents
    Retriever->>LLM: Format prompt with context
    LLM-->>Retriever: Generate medical answer
    Retriever->>Readability: Simplify to 6th grade level
    Readability-->>Retriever: Simplified answer + grade level
    Sources-->>Retriever: Source attribution
    Retriever->>Output: Save to results/answers.csv<br/>(question, answer, sources, 6th_grade_answer, grade_level)
    Output-->>User: Return results with readability scores
```

## ğŸ‰ Project Status

### âœ… Completed Features
- **RAG System**: Fully functional retrieval-augmented generation
- **Vector Database**: ChromaDB with persistent embeddings
- **Source Attribution**: Complete document tracking
- **Readability Enhancement**: Automatic 6th-grade simplification with Flesch-Kincaid scoring
- **Incremental Saving**: Robust progress preservation
- **Apple Silicon**: Optimized for M2 Max performance
- **Medical Q&A**: Successfully processed 49 medical questions
- **Production Ready**: Comprehensive error handling and logging

### ğŸ“Š Performance Results
- **Total Questions Processed**: 49/49 (100% completion)
- **Average Response Time**: ~50 seconds per question (including readability enhancement)
- **Source Accuracy**: 100% source attribution
- **Readability Success**: Average grade level 6.2 (target: 6.0)
- **Answer Quality**: Comprehensive medical responses with simplified versions
- **System Reliability**: Zero data loss with incremental saving

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
